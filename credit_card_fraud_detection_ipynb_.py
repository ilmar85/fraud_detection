# -*- coding: utf-8 -*-
"""Копия блокнота "Credit_Card_Fraud_Detection.ipynb"

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_XPOqrhZ1SyvibbEiLGsMnLUwYTbQ_OO

# **Обнаружение мошенничества с  банковскими транзакциями**

**Обнаружение мошенничест производилось путем:**
*   Классификации
*   Поиском выбросов
*   Нейронной сети

Анализ и предобработка:
"""

from datetime import datetime
import pandas as pd
import numpy as np
import seaborn as sns
import os
import random
import matplotlib
import matplotlib.pyplot as plt
from scipy import sparse
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn import svm
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import precision_score, precision_recall_curve
from sklearn.metrics import roc_auc_score, roc_curve, auc, average_precision_score
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from mlxtend.plotting import plot_confusion_matrix
import warnings
import itertools
warnings.filterwarnings('ignore')

from google.colab import drive
drive.mount('/content/drive')

# !wget https://www.dropbox.com/s/kvdn3ufqe1jlau3/creditcard.csv

data = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/set.csv")

# data = pd.read_csv("creditcard.csv")

data

df=data
df['Summ'].values.reshape(-1, 1)
df['Summ']=df['Summ'].str.replace('[^0-9]', '0') 
print(df)
df = df.drop(['Date_Of_transaction'], axis=1) 
stacked=data.stack()
data=pd.Series(stacked.factorize()[0],index=stacked.index,).unstack()
print(data)
i=data[:1]['Class'].values[0]
data['Class']=np.where(data['Class']==i,1,0)
data['Summ'] = StandardScaler().fit_transform(data['Summ'].values.reshape(-1, 1))
print(data)
data.dropna()

data=data.dropna(how="any")

data

"""Количество двух классов"""

counts = pd.value_counts(data.Class, sort = True)
counts.plot(kind = 'bar')
plt.show()
counts

"""Видно, что выборка несбалансированная

Посмотрим, поведение мошенников:
"""

# data_fraud = data[data['Class'] == 1] 
# plt.figure(figsize=(20,8))
# plt.scatter(data_fraud['Date_Of_transaction'], data_fraud['Summ']) 
# plt.title('Транзакции мошенников')
# plt.xlabel('Time')
# plt.ylabel('Amount')
# plt.xlim([0,175000])
# plt.ylim([0,2500])
# plt.show()

"""Посмотрим, как коррелируют переменные:"""

corr = data.corr()
plt.figure(figsize=(12,10))
heat = sns.heatmap(data=corr)

"""Сбалансирование выборки"""

data

data

df_train_all = data[800000:935300] 
df_train_all.dropna
df_train_1 = df_train_all[df_train_all['Class'] == 1] 
df_train_0 = df_train_all[df_train_all['Class'] == 0]

print("Кол-во транзакций мошенников: ", len(df_train_0))

df_train_0

df_train_1

df_sample=df_train_0.sample(300)
df_train = df_train_1.append(df_sample) 
df_train = df_train.sample(frac=1)

print(len(df_train))

X_train = df_train.drop(['Date_Of_transaction', 'Class'],axis=1)
y_train = df_train['Class']
X_train = np.asarray(X_train)
y_train = np.asarray(y_train)

X_train.shape

X_train = df_train.drop(['Date_Of_transaction', 'Class'],axis=1)

data.shape

"""Подготовим тренировочную выборку"""

df_test_all = data[906000:996500]

X_test_all = df_test_all.drop(['Date_Of_transaction', 'Class'],axis=1)
y_test_all = df_test_all['Class']
X_test_all = np.asarray(X_test_all)
y_test_all = np.asarray(y_test_all)

print('Тренировочная выборка содержит: ', len(df_test_all[df_test_all['Class'] == 0]), 'мошеннических транзакций')

df_test_all.shape

X_test_all.shape

X_train.shape

"""## **Классификация**

**Классификация SVM**
"""

cls = svm.SVC(kernel='linear')
cls.fit(X_train, y_train)

pred = cls.predict(X_test_all)

cm = confusion_matrix(y_test_all, pred)
plot_confusion_matrix(cm)

cm

from sklearn.metrics import accuracy_score

print('Accuracy: ', accuracy_score(y_test_all, pred))

from sklearn.tree import export_graphviz

"""**Случайный лес**"""

#visualizing RF
model = RandomForestClassifier(n_estimators=10)

# Train
model.fit(X_train, y_train)
# Extract single tree
estimator = model.estimators_[5]

from sklearn.tree import export_graphviz
# Export as dot file
export_graphviz(estimator, out_file='tree.dot', 
                feature_names = data.drop(['Date_Of_transaction', 'Class'], axis=1).columns.tolist(),
                class_names = ['0',' 1'],
                rounded = True, proportion = False, 
                precision = 2, filled = True)
# Convert to png
from subprocess import call
call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])
# Display in jupyter notebook
from IPython.display import Image
Image(filename = 'tree.png')

pred = model.predict(X_test_all)

print("Accuracy:", accuracy_score(y_test_all, pred))

cm = confusion_matrix(y_test_all, pred)
plot_confusion_matrix(cm)

cm

"""**LogisticRegression, LinearDiscriminantAnalysis, KNeighborsClassifier, DecisionTreeClassifier, SVC, XGBClassifier, RandomForestClassifier**"""

models = []

models.append(('LR', LogisticRegression()))
models.append(('LDA', LinearDiscriminantAnalysis()))
models.append(('KNN', KNeighborsClassifier()))
models.append(('CART', DecisionTreeClassifier()))
models.append(('SVM', SVC()))
models.append(('XGB', XGBClassifier()))
models.append(('RF', RandomForestClassifier()))

results = []
names = []

for name, model in models:
    kfold = KFold(n_splits=10, random_state=42)
    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='roc_auc')
    results.append(cv_results)
    names.append(name)
    print(name, ":", cv_results.mean())

results

"""Визуализация результатов"""

fig = plt.figure(figsize=(12,10))
plt.ylabel('ROC-AUC Score')
plt.boxplot(results)
ax = fig.add_subplot(111)
ax.set_xticklabels(names)
plt.show()

"""## **Поиск выбросов**

Так как транзакции мошенников это тоже выбросы, то можно произвести поиск выбросов

**IsolationForest**
"""

from sklearn.model_selection import train_test_split

X = data.drop(['Date_Of_transaction', 'Class'], axis =1 )
y = data['Class']

X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.8, random_state=42)

from sklearn.ensemble import IsolationForest

iforest = IsolationForest(contamination = 0.03,n_estimators = 100, max_samples = 0.6, max_features = 0.6,random_state = 42)
iforest.fit(X_train)

pred = iforest.predict(X_test_all)
for n, i in enumerate(pred):
  if i == 1:
    pred[n] = 1
  elif i == -1:
    pred[n] = 0
cm = confusion_matrix(y_test_all, pred)
plot_confusion_matrix(cm)

cm

"""**OneClassSVM**"""

one_svm = svm.OneClassSVM(nu = 0.03,kernel = 'rbf')
one_svm.fit(X_train)

pred = one_svm.predict(X_test_all)
for n, i in enumerate(pred):
  if i == 1:
    pred[n] = 1
  elif i == -1:
    pred[n] = 0
cm = confusion_matrix(y_test_all, pred)
plot_confusion_matrix(cm)

cm

"""## **Нейронная сеть**"""

from random import randint
from tensorflow import keras

df = data.copy()

"""Рандомизация выборки"""

x_stand=[]
y_stand=[]
for i in range(len(y)):
    if y[i]==1:
        x_stand.append(x[i])
        y_stand.append(1)
for r in range(2000):
    i=randint(0,len(y)-1)
    if y[i]==0:
        y_stand.append(0)
        x_stand.append(x[i])

x_stand=np.array(x_stand)
y_stand=np.array(y_stand)

"""Обучение"""

epochs=90
model = keras.Sequential([
    keras.layers.Dense(64,input_shape=(13,),activation='relu'),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(64,activation='relu'),
    keras.layers.Dense(2, activation='softmax')
])
print(model.summary())

model.compile(optimizer='Adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

historico=model.fit(x_stand, y_stand, epochs=epochs,validation_split=0.1,verbose=3)

"""Результат после использования для всей выборки"""

cm = confusion_matrix(y_true=np.array(y), y_pred=np.array([np.argmax(u)for u in model.predict(x)]))
plot_confusion_matrix(cm)
plt.show()

cm

data